# model-selection
A hands-on exploration of advanced model selection techniques in machine learning, including k-fold cross-validation, GridSearchCV, validation curves, and learning curves. It shows using scikit-learn on real and synthetic datasets to diagnose overfitting, underfitting, and optimize hyperparametersâ€”ensuring reliable models for production. 

## Features
This project covers the following topics:
* **K-Fold Cross-Validation:** Learn how to use K-Fold cross-validation to evaluate model performance and reduce overfitting risk.
* **Grid Search CV:** Discover how to automate hyperparameter tuning with GridSearchCV to find the optimal model configuration.
* **Validation and Learning Curves:** Diagnose model performance with validation and learning curves to identify issues like high bias or variance.

## Usage
To run the notebooks in this project, follow these steps:
1. Clone the repository:
```bash
git clone https://github.com/stkisengese/model-selection.git
cd model selection
```
2. Install the required dependencies:
```bash
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```
3. Launch Jupyter Notebook:
```bash
jupyter notebook
```
4. Open and run any of the .ipynb files to explore the different model selection techniques.

## License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.